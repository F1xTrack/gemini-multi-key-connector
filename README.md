# Умный прокси-сервер для Google Gemini API

Прокси-сервер, который автоматически управляет несколькими API-ключами Gemini для обхода лимитов Free Tier. Ключевые функции: ротация ключей, обработка ошибок квот (429), повторные попытки при перегрузке сервера (503), подсчет и сохранение использования токенов.

## Установка

1.  Клонируйте репозиторий (или просто скачайте файлы).
2.  Установите зависимости с помощью команды:
    ```bash
    pip install -r requirements.txt
    ```

## Конфигурация

Создайте файл `api_keys.json` в корне проекта со следующей структурой:

```json
[
  {
    "key": "ВАШ_ПЕРВЫЙ_API_КЛЮЧ",
    "token_usage": 0
  },
  {
    "key": "ВАШ_ВТОРОЙ_API_КЛЮЧ",
    "token_usage": 0
  }
]
```

## Запуск

```bash
# Для локального доступа
python proxy_server.py

# Для доступа из локальной сети или интернета
# ВНИМАНИЕ: Это сделает ваш прокси доступным для всех в вашей сети.
# Используйте, только если вы доверяете вашей сети.
# Запуск будет на 0.0.0.0:8080
```

## Использование

Этот прокси-сервер эмулирует эндпоинт, совместимый с OpenAI API. В качестве базового URL (`base_url` или `API Base`) в вашем клиенте (например, в веб-интерфейсе или скрипте) нужно использовать адрес запущенного сервера.

Клиенту нужно обращаться по адресу:
`http://ВАШ_IP_АДРЕС_СЕРВЕРА:8080/v1beta/models/gemini-pro:generateContent`

### Пример для клиентов, совместимых с OpenAI:

Для клиентов, которые ожидают OpenAI-совместимый API, нужно настроить `base_url` следующим образом:

*   **API Base URL:** `http://ВАШ_IP_АДРЕС_СЕРВЕРА:8080/v1beta/models`
*   **Model Name:** `gemini-pro:generateContent`
*   **API Key:** Можно указать любую строку, так как прокси управляет ключами самостоятельно.