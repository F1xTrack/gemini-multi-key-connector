# Умный прокси-сервер для Google Gemini API

Прокси-сервер, который автоматически управляет несколькими API-ключами Gemini для обхода лимитов Free Tier. Ключевые функции: ротация ключей, обработка ошибок квот (429), повторные попытки при перегрузке сервера (503), подсчет и сохранение использования токенов.

## Установка

1.  Клонируйте репозиторий (или просто скачайте файлы).
2.  Установите зависимости с помощью команды:
    ```bash
    pip install -r requirements.txt
    ```

## Конфигурация

Создайте файл `api_keys.json` в корне проекта. Новая структура позволяет отслеживать использование токенов и запросов для каждой модели отдельно.

*   `token_count`: общее количество использованных токенов.
*   `request_count`: общее количество запросов.
*   `rpd_limit_reached`: флаг, показывающий, достигнут ли дневной лимит запросов (true/false).

```json
[
  {
    "key": "ВАШ_ПЕРВЫЙ_API_КЛЮЧ",
    "usage": {
      "gemini-2.5-pro": {
        "token_count": 0,
        "request_count": 0,
        "rpd_limit_reached": false
      },
      "gemini-2.5-flash": {
        "token_count": 0,
        "request_count": 0,
        "rpd_limit_reached": false
      }
    }
  },
  {
    "key": "ВАШ_ВТОРОЙ_API_КЛЮЧ",
    "usage": {}
  }
]
```

## Запуск

```bash
# Для локального доступа
python proxy_server.py

# Для доступа из локальной сети или интернета
# ВНИМАНИЕ: Это сделает ваш прокси доступным для всех в вашей сети.
# Используйте, только если вы доверяете вашей сети.
# Запуск будет на 0.0.0.0:8080
```

## Тестирование

Для проверки работоспособности прокси-сервера после установки или внесения изменений, вы можете использовать автоматизированный скрипт `test_proxy.py`.

1.  **Запустите прокси-сервер**, как описано в разделе "Запуск":
    ```bash
    python proxy_server.py
    ```
2.  **В новом окне терминала** запустите тестовый скрипт:
    ```bash
    python test_proxy.py
    ```

Скрипт проверит основные эндпоинты: страницу статуса, список моделей и эндпоинт для чат-комплишенов. В случае успеха вы увидите сообщения `PASSED` для каждого теста.

## Страница статуса

Для мониторинга состояния API-ключей в реальном времени была добавлена HTML-страница. Она доступна по корневому URL-адресу вашего сервера:

`http://ВАШ_IP_АДРЕС_СЕРВЕРА:8080/`

На этой странице отображается:
*   Общее количество загруженных ключей.
*   Статистика по каждому ключу:
    *   Использованные модели.
    *   Количество токенов и запросов для каждой модели.
    *   Статус дневного лимита запросов (RPD).

## Использование

Эндпоинт сервера теперь является динамическим и принимает имя модели как часть URL. Это позволяет прокси-серверу применять лимиты для каждой модели индивидуально.

Примеры URL для разных моделей:
*   `http://ВАШ_IP_АДРЕС_СЕРВЕРА:8080/v1beta/models/gemini-2.5-pro:generateContent`
*   `http://ВАШ_IP_АДРЕС_СЕРВЕРА:8080/v1beta/models/gemini-2.5-flash:generateContent`

### Пример для клиентов, совместимых с OpenAI:

*   **API Base URL:** `http://ВАШ_IP_АДРЕС_СЕРВЕРА:8080/v1`
*   **Model Name:** `gemini-2.5-pro` (или любая другая поддерживаемая модель).
*   **API Key:** Можно указать любую строку, так как прокси управляет ключами самостоятельно.

### Получение списка моделей

Для клиентов, которые поддерживают стандартный эндпоинт OpenAI для получения списка моделей, был добавлен соответствующий маршрут. Это позволяет некоторым программам автоматически определять доступные модели.

Для получения списка моделей сделайте GET-запрос на эндпоинт:
`http://ВАШ_IP_АДРЕС_СЕРВЕРА:8080/v1/models`